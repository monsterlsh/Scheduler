{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('hello zz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "sys.path.append('./Scheduler')\n",
    "print(sys)\n",
    "from data.loader import InstanceConfigLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "a = random.randint(1,10)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "\n",
    "class Trigger(ABC):\n",
    "    @abstractmethod\n",
    "    def __call__(self, cluster, clock):\n",
    "        pass\n",
    "\n",
    "\n",
    "class ThresholdTrigger(Trigger):\n",
    "    def __call__(self, cluster, clock, cpu_threshold=0.55, memory_threshold=0.55, disk_threshold=0.55):\n",
    "        print(cluster,disk_threshold)\n",
    "\n",
    "triger = ThresholdTrigger()\n",
    "triger('1',2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rd\n",
    "for i in  range(1,10):\n",
    "    next = rd.randint(1,10)\n",
    "    print(f'{i},next random in 1-10 is{next}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "cpulist = {1:[1,2,3],2:[1,2,3]}\n",
    "cpu = np.array([v for k,v in cpulist.items()])\n",
    "cpu.shape[0]\n",
    "cpu = np.zeros(shape=(3,4))\n",
    "cpu[0][1]=2\n",
    "cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试添加machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "sys.path.append('./Scheduler')\n",
    "from data.loader import InstanceConfigLoader\n",
    "from framework.algorithm import ThresholdFirstFitAlgorithm\n",
    "#from framework.instance import InstanceConfig\n",
    "from framework.machine import MachineConfig\n",
    "from framework.simulation import Simulation\n",
    "from framework.trigger import ThresholdTrigger\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    instance_number = 20\n",
    "    machine_number = int(instance_number/2+instance_number/4)\n",
    "    machine_configs = []\n",
    "    for id in range(machine_number):\n",
    "        machine = MachineConfig(id,300,20,20)\n",
    "        machine_configs.append(machine)\n",
    "    macFile = '/Users/lsh/Documents/ecnuIcloud/Trace/alibaba_2018/intp_dir'\n",
    "    windowsFile = 'D:\\Data\\workplace\\ecnuicloud\\Traces\\intp_dir\\\\'\n",
    "    linux_file = '/hdd/sxy/Trace_alibaba2018/alibaba_2018/intp_dir'\n",
    "    instance_configs = InstanceConfigLoader(linux_file,instance_number)\n",
    "    sim = Simulation(machine_configs, instance_configs, ThresholdTrigger(), ThresholdFirstFitAlgorithm())\n",
    "    sim.run()\n",
    "\n",
    "    #print(sim.cluster.structure)\n",
    "    struct = sim.cluster.structure\n",
    "    filename = './struct.json'\n",
    "    with open(filename,'w') as file_job:\n",
    "        json.dump(struct,file_job)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "env = simpy.Environment()\n",
    "trigger = ThresholdTrigger()\n",
    "trigger(cluster,env)\n",
    "macid_to_schedule = []\n",
    "insid_to_schedule=[]\n",
    "for macid in cluster.machines_to_schedule:\n",
    "    macid_to_schedule.append(macid.id)\n",
    "\n",
    "instances_to_reschedule = [inst \\\n",
    "    for machine in cluster.machines_to_schedule \\\n",
    "        for inst in machine.instances.values()]\n",
    "        \n",
    "for ins in instances_to_reschedule:\n",
    "    insid_to_schedule.append(ins.id)\n",
    "print('machine id to schedule',macid_to_schedule)\n",
    "print('instance id to schedule',insid_to_schedule)\n",
    "# for instance, instance_cpu_curve in instance_cpu_curves.items():\n",
    "#     print(instance.id,f'next is its type {type(instance_cpu_curve)} cpus:',\\\n",
    "#         instance_cpu_curve)\n",
    "algorithm = ThresholdFirstFitAlgorithm()\n",
    "algorithm(cluster,env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 其他python测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python 类属性测试\n",
    "class A:\n",
    "    def __init__(self,name):\n",
    "        self.name = name\n",
    "    @property\n",
    "    def cpu(self):\n",
    "        return 2\n",
    "    @property\n",
    "    def test(self):\n",
    "        return self.cpu\n",
    "    def setName(self,name):\n",
    "        self.name = name\n",
    "    def algo(self):\n",
    "        return 1,2,3\n",
    "a,b,c =A('abc'),A('bcd'),A('eeee')\n",
    "demo = [a,b,c]\n",
    "for deo in demo:\n",
    "    deo.name = 'change2'\n",
    "print(a.name,b.name,c.name)\n",
    "ares = a.algo()\n",
    "ares[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test dict remove list\n",
    "demo = {1:[1,2,3,4],\n",
    "2:[1,2,3,4],\n",
    "3:[1,2,3,4],\n",
    "4:[1,2,3,4],\n",
    "5:[1,2,3,4],\n",
    "6:[1,2,3,4],\n",
    "7:[1,2,3,4]}\n",
    "print('lase: ',demo)\n",
    "print('next:')\n",
    "for key,value in demo.items():\n",
    "    value.pop(1)\n",
    "    # print(value)\n",
    "    # demo[key]=value\n",
    "print('new:',demo)\n",
    "len(demo.items())\n",
    "demo.get(2,None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在for循环中remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sq(x):\n",
    "    return x*x\n",
    "\n",
    "map(sq,[y for y in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 字典排序测试\n",
    "machines = cluster.machines\n",
    "\n",
    "for k,v in machines.items():\n",
    "    print('old:',k,v.cpu)\n",
    "#对值排序\n",
    "machines = {k:v for k,v in sorted(machines.items(),key= lambda x:x[1].cpu,reverse=True)}\n",
    "for k,v in machines.items():\n",
    "    print(v.cpu)\n",
    "# machine_id = [ids for ids,cpu in machine_id_cpu.itms()]\n",
    "# print('after sort:',machine_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 集合添加 测试\n",
    "\n",
    "def mylist_toset(lists):\n",
    "    lists[0]=1000\n",
    "\n",
    "myset = set()\n",
    "mylist = list([100,2,3])\n",
    "myset.update(mylist)\n",
    "a = myset.pop()\n",
    "myset.clear()\n",
    "if myset:\n",
    "    print('22')\n",
    "else:\n",
    "    print('clear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myset = set()\n",
    "mylist = list([100,2,3,1])\n",
    "myset.update(mylist)\n",
    "print(next(iter(mylist)),next(iter(myset)),next(iter(myset)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd(),os.pardir\n",
    "dicts = {1:2,100:3,3:4}\n",
    "sorted(dicts.items(),key=lambda x:x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试Main "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.pardir)\n",
    "from data.loader import InstanceConfigLoader\n",
    "from framework.algorithm import ThresholdFirstFitAlgorithm,SchdeulerPolicyAlgorithm\n",
    "from framework.instance import InstanceConfig\n",
    "from framework.machine import MachineConfig\n",
    "from framework.simulation import Simulation\n",
    "from framework.trigger import ThresholdTrigger\n",
    "\n",
    "import json\n",
    "\n",
    "# res_struct_filename = os.path.join(os.getcwd(),'struct.json')\n",
    "instance_number = 20\n",
    "machine_number = int(instance_number/2+instance_number/4)\n",
    "machine_configs = []\n",
    "for id in range(machine_number):\n",
    "    machine = MachineConfig(id,300,20,20)\n",
    "    machine_configs.append(machine)\n",
    "macFile = '/Users/lsh/Documents/ecnuIcloud/Trace/alibaba_2018/intp_dir'\n",
    "windowsFile = 'D:\\Data\\workplace\\ecnuicloud\\Traces\\intp_dir\\\\'\n",
    "linux_file = '/hdd/sxy/Trace_alibaba2018/alibaba_2018/intp_dir'\n",
    "instance_configs = InstanceConfigLoader(linux_file,instance_number)\n",
    "sim = Simulation(machine_configs, instance_configs, ThresholdTrigger(), ThresholdFirstFitAlgorithm(),SchdeulerPolicyAlgorithm())\n",
    "sim.run()\n",
    "\n",
    "print(sim.cluster.structure)\n",
    "# struct = sim.cluster.structure\n",
    "# with open(res_struct_filename,'w') as file_job:\n",
    "#     json.dump(struct,file_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试SXY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = np.empty(shape=[1,5])\n",
    "x= np.zeros(shape=(5))\n",
    "cpu = np.random.randint(0,10,(4,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_min = 0\n",
    "W = 3\n",
    "print(cpu)\n",
    "for t in range(W):\n",
    "    cpu_t = cpu[:, t] # 提取cpu矩阵中第t-1列，比如t=0即提取下一时刻各VM的cpu需求量\n",
    "    print(cpu_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试python多态\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "class Algorithm(ABC):\n",
    "    @abstractmethod\n",
    "    def __call__(self, *args):\n",
    "        pass\n",
    "\n",
    "class ThresholdFirstFitAlgorithm(Algorithm):\n",
    "    def __call__(self, cluster, clock):\n",
    "        print('there is ThresholdFirstFitAlgorithm')\n",
    "class RandomSampleAlgorithm(Algorithm):\n",
    "    def __call__(self, cluster:list,env,lis):\n",
    "        print('there is Random sample')\n",
    "def test(algo):\n",
    "    algo('1','2')\n",
    "test(ThresholdFirstFitAlgorithm())\n",
    "test(RandomSampleAlgorithm())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多资源测试\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "filepath = '/hdd/jbinin/alibaba2018_data_extraction/data/hole'\n",
    "def read_list():\n",
    "    files = os.listdir(filepath)\n",
    "    for file in files:\n",
    "        with open(file) as f:\n",
    "            cpus = pd.read_csv(f)\n",
    "            print(cpus)\n",
    "def read_iterator(filepath):\n",
    "    i = 0\n",
    "    with os.scandir(filepath) as entries:\n",
    "        for entry in entries:\n",
    "            if entry.is_file():\n",
    "                filename = os.path.join(filepath, entry.name)\n",
    "                #print(filename)\n",
    "                with open(filename) as f:\n",
    "                    cpus = pd.read_csv(f,header=None)\n",
    "                    return cpus[0].values.squeeze().tolist(),cpus[1].values.squeeze().tolist()\n",
    "\n",
    "cpus,mem  = read_iterator(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import json\n",
    "import sys\n",
    "sys.path.append('./Scheduler')\n",
    "from data.loader import InstanceConfigLoader\n",
    "from framework.algorithm import ThresholdFirstFitAlgorithm,SchdeulerPolicyAlgorithm\n",
    "from framework.machine import MachineConfig\n",
    "from framework.simulation import Simulation\n",
    "from framework.trigger import ThresholdTrigger\n",
    "def test_all():\n",
    "    #res_struct_filename = os.path.join(os.getcwd(),'struct.json')\n",
    "    \n",
    "    \n",
    "    sim = Simulation(machine_configs, instance_configs, ThresholdTrigger(), ThresholdFirstFitAlgorithm(),SchdeulerPolicyAlgorithm())\n",
    "    sim.run()\n",
    "    struct = sim.cluster.structure\n",
    "    # with open(res_struct_filename,'w') as file_job:\n",
    "    #     json.dump(struct,file_job)\n",
    "    # pass\n",
    "\n",
    "macFile = '/Users/lsh/Documents/ecnuIcloud/Trace/alibaba_2018/intp_dir'\n",
    "windowsFile = 'D:\\Data\\workplace\\ecnuicloud\\Traces\\intp_dir\\\\'\n",
    "linux_file = '/hdd/jbinin/alibaba2018_data_extraction/data/hole'\n",
    "linux_file = '/hdd/jbinin/AlibabaData/target/'\n",
    "instance_configs,machine_configs = InstanceConfigLoader(linux_file)\n",
    "#test_all()\n",
    "#simple_test(linux_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "nplist = np.array([1,2,3,4,5])\n",
    "\n",
    "any_over = np.where(nplist>3)[0]\n",
    "source = np.random.choice(any_over, 1, replace = False)\n",
    "any_over.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path=r\"d:\\20200708002140.jpg\"\n",
    "base_name=os.path.splitext(file_path)[0]\n",
    " \n",
    "print(base_name)\n",
    " \n",
    "file_extension=os.path.splitext(file_path)[1]\n",
    "print(file_extension)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "inc_mac_id_file = '/hdd/lsh/Scheduler/data/container_machine_id.csv'\n",
    "df = pd.read_csv(inc_mac_id_file,names=['cpuid','memid'])\n",
    "# for idx,data in df.iterrows():\n",
    "#     print(\"[{}]: {}\".format(data['cpuid'],data['memid']))\n",
    "df['cpuid'][0],df['memid'][0]\n",
    "filename = 'adasd_23.csv'\n",
    "incid = int(filename[filename.find('_')+1:-4])\n",
    "incid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "c = {'1':[2,3,4],'c':[4,5,6],'b':[4,6,7]}\n",
    "a = np.array([predicts for inc_id,predicts in c.items()])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "filename = '/hdd/lsh/Scheduler/arima/model.csv'\n",
    "df = pd.read_csv(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8563\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "filename = '/hdd/lsh/Scheduler/arima/model'\n",
    "files = os.listdir(filename)\n",
    "print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, 1])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_last = np.array([[0,1,2,3],[1,2,3,4],[1,3,4,5]])\n",
    "mig_candi_s = np.where(x_last[:, 0] == 1)[0]\n",
    "np.random.choice(mig_candi_s, int(np.ceil(int(2* len(mig_candi_s)))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  statsmodels.tsa.arima.model import  ARIMA\n",
    "from statsmodels.tsa.arima.model import ARIMAResults\n",
    "import pmdarima  \n",
    "cpu =np.random.randint(1,100,size=30)\n",
    "\n",
    "model = pmdarima.auto_arima(cpu,start_p=0,start_q=0,alpha=0.01, trace=True,stepwise=False,suppress_warnings=True,error_action='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ARIMA(cpu, order=(5,0,0)).fit() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ARIMA(0,0,0)(0,0,0)[1] intercept   : AIC=-502.486, Time=0.03 sec\n",
      " ARIMA(0,0,1)(0,0,0)[1] intercept   : AIC=-579.513, Time=0.04 sec\n",
      " ARIMA(0,0,2)(0,0,0)[1] intercept   : AIC=-602.055, Time=0.08 sec\n",
      " ARIMA(0,0,3)(0,0,0)[1] intercept   : AIC=-619.030, Time=0.11 sec\n",
      " ARIMA(0,0,4)(0,0,0)[1] intercept   : AIC=-620.503, Time=0.18 sec\n",
      " ARIMA(0,0,5)(0,0,0)[1] intercept   : AIC=-631.733, Time=0.25 sec\n",
      " ARIMA(1,0,0)(0,0,0)[1] intercept   : AIC=-621.386, Time=0.05 sec\n",
      " ARIMA(1,0,1)(0,0,0)[1] intercept   : AIC=-620.460, Time=0.08 sec\n",
      " ARIMA(1,0,2)(0,0,0)[1] intercept   : AIC=-618.645, Time=0.06 sec\n",
      " ARIMA(1,0,3)(0,0,0)[1] intercept   : AIC=-617.444, Time=0.17 sec\n",
      " ARIMA(1,0,4)(0,0,0)[1] intercept   : AIC=-619.038, Time=0.24 sec\n",
      " ARIMA(2,0,0)(0,0,0)[1] intercept   : AIC=-620.381, Time=0.05 sec\n",
      " ARIMA(2,0,1)(0,0,0)[1] intercept   : AIC=-618.600, Time=0.17 sec\n",
      " ARIMA(2,0,2)(0,0,0)[1] intercept   : AIC=-618.451, Time=0.16 sec\n",
      " ARIMA(2,0,3)(0,0,0)[1] intercept   : AIC=-616.357, Time=0.19 sec\n",
      " ARIMA(3,0,0)(0,0,0)[1] intercept   : AIC=-618.671, Time=0.11 sec\n",
      " ARIMA(3,0,1)(0,0,0)[1] intercept   : AIC=-616.626, Time=0.18 sec\n",
      " ARIMA(3,0,2)(0,0,0)[1] intercept   : AIC=-614.120, Time=0.21 sec\n",
      " ARIMA(4,0,0)(0,0,0)[1] intercept   : AIC=-616.926, Time=0.12 sec\n",
      " ARIMA(4,0,1)(0,0,0)[1] intercept   : AIC=-614.671, Time=0.12 sec\n",
      " ARIMA(5,0,0)(0,0,0)[1] intercept   : AIC=-619.919, Time=0.20 sec\n",
      "\n",
      "Best model:  ARIMA(0,0,5)(0,0,0)[1] intercept\n",
      "Total fit time: 2.808 seconds\n",
      "SARIMAX(0, 0, 5)\n"
     ]
    }
   ],
   "source": [
    "from auto_ts import auto_timeseries\n",
    "from dateutil.parser import parse\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pmdarima \n",
    "file = '/hdd/jbinin/AlibabaData/target/instanceid_30288.csv'\n",
    "data = pd.read_csv(file,header=None)\n",
    "data.columns=['cpulist','memlist']\n",
    "lens = int(len(data)*0.7)\n",
    "df = np.array(data[:lens]['cpulist'])\n",
    "dftest = np.array(data[lens:lens+10]['cpulist'])\n",
    "df_mem = np.array(data[:lens]['memlist'])\n",
    "model = pmdarima.arima.auto_arima(df,start_p=0,start_q=0,alpha=0.01, trace=True,stepwise=False,suppress_warnings=True,error_action='ignore')\n",
    "pqd = model.summary().tables[0].data[1][1]\n",
    "print(pqd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67437"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "inc_mac_id_file = '/hdd/lsh/Scheduler/data/container_machine_id.csv'\n",
    "df = pd.read_csv(inc_mac_id_file,header = None)\n",
    "a = [idx for idx,data in df.iterrows()]\n",
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140642539623312\n",
      "140641880764848\n",
      "x\n",
      "y\n",
      "a\n",
      "140641880764848\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gc\n",
    "def f(x,y):\n",
    "    x1 = x.copy()\n",
    "    print(id(x1))\n",
    "    a = x1\n",
    "    a[0]=100\n",
    "    \n",
    "    del x1\n",
    "    \n",
    "    gc.collect()\n",
    "    for x in locals().keys():\n",
    "        print(x)\n",
    "    return a\n",
    "x = np.array([1,2,3,4])\n",
    "y = np.array([2.3,3.4,4.1,5])\n",
    "print(id(x))\n",
    "x= f(x,y)\n",
    "print(id(x))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b26ffe065d98ea7a5273c6f6fba4ea3298940a306d2e17ef60b9693bc7ffaea0"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
